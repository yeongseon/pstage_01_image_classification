{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b8135f2",
   "metadata": {},
   "source": [
    "## 0. Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "built-elevation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터셋 폴더 경로를 지정해주세요.\n",
    "TRAIN_DIR = \"/Users/yeongseon/Downloads/train/train/images\"\n",
    "MODEL_DIR = \"./model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3e92b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = { \n",
    "    \"seed\": 42,\n",
    "    \"epochs\": 3,\n",
    "    \"dataset\": \"MaskBaseDataset\",\n",
    "    \"augmentation\": \"BaseAugmentation\",\n",
    "    \"resize\": [128, 96],\n",
    "    \"train_batch_size\": 64,\n",
    "    \"valid_batch_size\": 1000,\n",
    "    \"model\" : \"BaseModel\",\n",
    "    \"optimizer\": \"SGD\",\n",
    "    \"lr\": 1e-3,\n",
    "    \"val_ratio\": 0.2,\n",
    "    \"criterion\": \"cross_entropy\",\n",
    "    \"lr_decay_step\": 20,\n",
    "    \"log_interval\": 20,\n",
    "    \"name\": \"exp\",\n",
    "    \"data_dir\": TRAIN_DIR,\n",
    "    \"model_dir\": MODEL_DIR\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0e793d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "seed = params[\"seed\"]\n",
    "\n",
    "def seed_everything(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "# Initialize random seed\n",
    "seed_everything(seed)\n",
    "\n",
    "# device optimization\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f8042f",
   "metadata": {},
   "source": [
    "## 1. Test Dataset 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffbda96f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4293227174.py, line 49)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [4]\u001b[0;36m\u001b[0m\n\u001b[0;31m    class from PIL import Image\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from enum import Enum\n",
    "from typing import Tuple\n",
    "from torch.utils.data import Dataset, Subset, random_split\n",
    "\n",
    "class MaskLabels(int, Enum):\n",
    "    MASK = 0\n",
    "    INCORRECT = 1\n",
    "    NORMAL = 2\n",
    "\n",
    "\n",
    "class GenderLabels(int, Enum):\n",
    "    MALE = 0\n",
    "    FEMALE = 1\n",
    "\n",
    "    @classmethod\n",
    "    def from_str(cls, value: str) -> int:\n",
    "        value = value.lower()\n",
    "        if value == \"male\":\n",
    "            return cls.MALE\n",
    "        elif value == \"female\":\n",
    "            return cls.FEMALE\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Gender value should be either 'male' or 'female', {value}\"\n",
    "            )\n",
    "\n",
    "\n",
    "class AgeLabels(int, Enum):\n",
    "    YOUNG = 0\n",
    "    MIDDLE = 1\n",
    "    OLD = 2\n",
    "\n",
    "    @classmethod\n",
    "    def from_number(cls, value: str) -> int:\n",
    "        try:\n",
    "            value = int(value)\n",
    "        except Exception:\n",
    "            raise ValueError(f\"Age value should be numeric, {value}\")\n",
    "\n",
    "        if value < 30:\n",
    "            return cls.YOUNG\n",
    "        elif value < 60:\n",
    "            return cls.MIDDLE\n",
    "        else:\n",
    "            return cls.OLD\n",
    "\n",
    "\n",
    "class MaskBaseDataset(Dataset):\n",
    "    num_classes = 3 * 2 * 3\n",
    "\n",
    "    _file_names = {\n",
    "        \"mask1\": MaskLabels.MASK,\n",
    "        \"mask2\": MaskLabels.MASK,\n",
    "        \"mask3\": MaskLabels.MASK,\n",
    "        \"mask4\": MaskLabels.MASK,\n",
    "        \"mask5\": MaskLabels.MASK,\n",
    "        \"incorrect_mask\": MaskLabels.INCORRECT,\n",
    "        \"normal\": MaskLabels.NORMAL,\n",
    "    }\n",
    "\n",
    "    image_paths = []\n",
    "    mask_labels = []\n",
    "    gender_labels = []\n",
    "    age_labels = []\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir,\n",
    "        mean=(0.548, 0.504, 0.479),\n",
    "        std=(0.237, 0.247, 0.246),\n",
    "        val_ratio=0.2,\n",
    "    ):\n",
    "        self.data_dir = data_dir\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.val_ratio = val_ratio\n",
    "\n",
    "        self.transform = None\n",
    "        self.setup()\n",
    "        self.calc_statistics()\n",
    "\n",
    "    def setup(self):\n",
    "        profiles = os.listdir(self.data_dir)\n",
    "        for profile in profiles:\n",
    "            if profile.startswith(\".\"):  # \".\" 로 시작하는 파일은 무시합니다\n",
    "                continue\n",
    "\n",
    "            img_folder = os.path.join(self.data_dir, profile)\n",
    "            for file_name in os.listdir(img_folder):\n",
    "                _file_name, ext = os.path.splitext(file_name)\n",
    "                if (\n",
    "                    _file_name not in self._file_names\n",
    "                ):  # \".\" 로 시작하는 파일 및 invalid 한 파일들은 무시합니다\n",
    "                    continue\n",
    "\n",
    "                img_path = os.path.join(\n",
    "                    self.data_dir, profile, file_name\n",
    "                )  # (resized_data, 000004_male_Asian_54, mask1.jpg)\n",
    "                mask_label = self._file_names[_file_name]\n",
    "\n",
    "                id, gender, race, age = profile.split(\"_\")\n",
    "                gender_label = GenderLabels.from_str(gender)\n",
    "                age_label = AgeLabels.from_number(age)\n",
    "\n",
    "                self.image_paths.append(img_path)\n",
    "                self.mask_labels.append(mask_label)\n",
    "                self.gender_labels.append(gender_label)\n",
    "                self.age_labels.append(age_label)\n",
    "\n",
    "    def calc_statistics(self):\n",
    "        has_statistics = self.mean is not None and self.std is not None\n",
    "        if not has_statistics:\n",
    "            print(\n",
    "                \"[Warning] Calculating statistics... It can take a long time depending on your CPU machine\"\n",
    "            )\n",
    "            sums = []\n",
    "            squared = []\n",
    "            for image_path in self.image_paths[:3000]:\n",
    "                image = np.array(Image.open(image_path)).astype(np.int32)\n",
    "                sums.append(image.mean(axis=(0, 1)))\n",
    "                squared.append((image ** 2).mean(axis=(0, 1)))\n",
    "\n",
    "            self.mean = np.mean(sums, axis=0) / 255\n",
    "            self.std = (np.mean(squared, axis=0) - self.mean ** 2) ** 0.5 / 255\n",
    "\n",
    "    def set_transform(self, transform):\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        assert self.transform is not None, \".set_tranform 메소드를 이용하여 transform 을 주입해주세요\"\n",
    "\n",
    "        image = self.read_image(index)\n",
    "        mask_label = self.get_mask_label(index)\n",
    "        gender_label = self.get_gender_label(index)\n",
    "        age_label = self.get_age_label(index)\n",
    "        multi_class_label = self.encode_multi_class(mask_label, gender_label, age_label)\n",
    "\n",
    "        image_transform = self.transform(image)\n",
    "        return image_transform, multi_class_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def get_mask_label(self, index) -> MaskLabels:\n",
    "        return self.mask_labels[index]\n",
    "\n",
    "    def get_gender_label(self, index) -> GenderLabels:\n",
    "        return self.gender_labels[index]\n",
    "\n",
    "    def get_age_label(self, index) -> AgeLabels:\n",
    "        return self.age_labels[index]\n",
    "\n",
    "    def read_image(self, index):\n",
    "        image_path = self.image_paths[index]\n",
    "        return Image.open(image_path)\n",
    "\n",
    "    @staticmethod\n",
    "    def encode_multi_class(mask_label, gender_label, age_label) -> int:\n",
    "        return mask_label * 6 + gender_label * 3 + age_label\n",
    "\n",
    "    @staticmethod\n",
    "    def decode_multi_class(\n",
    "        multi_class_label,\n",
    "    ) -> Tuple[MaskLabels, GenderLabels, AgeLabels]:\n",
    "        mask_label = (multi_class_label // 6) % 3\n",
    "        gender_label = (multi_class_label // 3) % 2\n",
    "        age_label = multi_class_label % 3\n",
    "        return mask_label, gender_label, age_label\n",
    "\n",
    "    @staticmethod\n",
    "    def denormalize_image(image, mean, std):\n",
    "        img_cp = image.copy()\n",
    "        img_cp *= std\n",
    "        img_cp += mean\n",
    "        img_cp *= 255.0\n",
    "        img_cp = np.clip(img_cp, 0, 255).astype(np.uint8)\n",
    "        return img_cp\n",
    "\n",
    "    def split_dataset(self) -> Tuple[Subset, Subset]:\n",
    "        \"\"\"\n",
    "        데이터셋을 train 과 val 로 나눕니다,\n",
    "        pytorch 내부의 torch.utils.data.random_split 함수를 사용하여\n",
    "        torch.utils.data.Subset 클래스 둘로 나눕니다.\n",
    "        구현이 어렵지 않으니 구글링 혹은 IDE (e.g. pycharm) 의 navigation 기능을 통해 코드를 한 번 읽어보는 것을 추천드립니다^^\n",
    "        \"\"\"\n",
    "        n_val = int(len(self) * self.val_ratio)\n",
    "        n_train = len(self) - n_val\n",
    "        train_set, val_set = random_split(self, [n_train, n_val])\n",
    "        return train_set, val_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76813d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "\n",
    "\n",
    "class BaseAugmentation:\n",
    "    def __init__(self, resize, mean, std, **args):\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                Resize(resize, Image.BILINEAR),\n",
    "                ToTensor(),\n",
    "                Normalize(mean=mean, std=std),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __call__(self, image):\n",
    "        return self.transform(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55207f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of subprocess to use for data loading\n",
    "num_workers = 0\n",
    "\n",
    "# how manhy sample per batch to load\n",
    "train_batch_size = params[\"train_batch_size\"]\n",
    "valid_batch_size = params[\"valid_batch_size\"]\n",
    "\n",
    "# \n",
    "val_ratio = params[\"val_ratio\"]\n",
    "\n",
    "resize = params[\"resize\"]\n",
    "\n",
    "dataset = MaskBaseDataset(data_dir=TRAIN_DIR, val_ratio=val_ratio)\n",
    "\n",
    "# Argumentation\n",
    "transform = BaseAugmentation(\n",
    "    resize=resize,\n",
    "    mean=dataset.mean,\n",
    "    std=dataset.std,\n",
    ")\n",
    "dataset.set_transform(transform)\n",
    "\n",
    "# data loader\n",
    "train_set, val_set = dataset.split_dataset()\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size=train_batch_size,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=True,\n",
    "    pin_memory=use_cuda,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_set,\n",
    "    batch_size=valid_batch_size,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=False,\n",
    "    pin_memory=use_cuda,\n",
    "    drop_last=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-organizer",
   "metadata": {},
   "source": [
    "## 2. Model 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-easter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, num_classes: int = 1000):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(32, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the Model\n",
    "model = BaseModel(num_classes=dataset.num_classes)\n",
    "model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce7e474",
   "metadata": {},
   "source": [
    "### Loss Function Optimizer 정의 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0399cdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = params[\"lr\"]\n",
    "\n",
    "# Specifiy loss funtion\n",
    "criterion = nn.CrossEntropyLoss() # categorical cross-entryopy\n",
    "\n",
    "# Specify optimer\n",
    "optimizer = torch.optim.SGD(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=lr,\n",
    "    weight_decay=5e-4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c3c659",
   "metadata": {},
   "source": [
    "## 3. 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3baef740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group[\"lr\"]\n",
    "\n",
    "def grid_image(np_images, gts, preds, n=16, shuffle=False):\n",
    "    batch_size = np_images.shape[0]\n",
    "    assert n <= batch_size\n",
    "\n",
    "    choices = random.choices(range(batch_size), k=n) if shuffle else list(range(n))\n",
    "    figure = plt.figure(\n",
    "        figsize=(12, 18 + 2)\n",
    "    )  # cautions: hardcoded, 이미지 크기에 따라 figsize 를 조정해야 할 수 있습니다. T.T\n",
    "    plt.subplots_adjust(\n",
    "        top=0.8\n",
    "    )  # cautions: hardcoded, 이미지 크기에 따라 top 를 조정해야 할 수 있습니다. T.T\n",
    "    n_grid = np.ceil(n ** 0.5)\n",
    "    tasks = [\"mask\", \"gender\", \"age\"]\n",
    "    for idx, choice in enumerate(choices):\n",
    "        gt = gts[choice].item()\n",
    "        pred = preds[choice].item()\n",
    "        image = np_images[choice]\n",
    "        # title = f\"gt: {gt}, pred: {pred}\"\n",
    "        gt_decoded_labels = MaskBaseDataset.decode_multi_class(gt)\n",
    "        pred_decoded_labels = MaskBaseDataset.decode_multi_class(pred)\n",
    "        title = \"\\n\".join(\n",
    "            [\n",
    "                f\"{task} - gt: {gt_label}, pred: {pred_label}\"\n",
    "                for gt_label, pred_label, task in zip(\n",
    "                    gt_decoded_labels, pred_decoded_labels, tasks\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        plt.subplot(n_grid, n_grid, idx + 1, title=title)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(image, cmap=plt.cm.binary)\n",
    "\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c42397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "def increment_path(path, exist_ok=False):\n",
    "    \"\"\"Automatically increment path, i.e. runs/exp --> runs/exp0, runs/exp1 etc.\n",
    "\n",
    "    Args:\n",
    "        path (str or pathlib.Path): f\"{model_dir}/{args.name}\".\n",
    "        exist_ok (bool): whether increment path (increment if False).\n",
    "    \"\"\"\n",
    "    path = Path(path)\n",
    "    if (path.exists() and exist_ok) or (not path.exists()):\n",
    "        return str(path)\n",
    "    else:\n",
    "        dirs = glob.glob(f\"{path}*\")\n",
    "        matches = [re.search(rf\"%s(\\d+)\" % path.stem, d) for d in dirs]\n",
    "        i = [int(m.groups()[0]) for m in matches if m]\n",
    "        n = max(i) + 1 if i else 2\n",
    "        return f\"{path}{n}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c4769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "epochs = params[\"epochs\"]\n",
    "model_dir = params[\"model_dir\"]\n",
    "log_interval = params[\"log_interval\"]\n",
    "\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer, step_size=20, gamma=0.5\n",
    ")\n",
    "\n",
    "save_dir = increment_path(os.path.join(model_dir, \"exp\"))\n",
    "\n",
    "# writer will output to save_dir\n",
    "writer = SummaryWriter(log_dir=save_dir)\n",
    "\n",
    "with open(os.path.join(save_dir, \"config.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(params, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "best_val_acc = 0\n",
    "best_val_loss = np.inf\n",
    "\n",
    "# epoch training loop\n",
    "for epoch in range(epochs):\n",
    "    # train loop\n",
    "    model.train()\n",
    "    loss_value = 0\n",
    "    matches = 0\n",
    "\n",
    "    # batch training loop\n",
    "    for idx, train_batch in enumerate(train_loader):\n",
    "        inputs, labels = train_batch\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outs = model(inputs)\n",
    "        preds = torch.argmax(outs, dim=-1)\n",
    "        loss = criterion(outs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_value += loss.item()\n",
    "        matches += (preds == labels).sum().item()\n",
    "        if (idx + 1) % log_interval == 0:\n",
    "            train_loss = loss_value / log_interval\n",
    "            train_acc = matches / train_batch_size / log_interval\n",
    "            current_lr = get_lr(optimizer)\n",
    "            print(\n",
    "                f\"Epoch[{epoch}/{epochs}]({idx + 1}/{len(train_loader)}) || \"\n",
    "                f\"training loss {train_loss:4.4} || training accuracy {train_acc:4.2%} || lr {current_lr}\"\n",
    "            )\n",
    "            writer.add_scalar(\n",
    "                \"Train/loss\", train_loss, epoch * len(train_loader) + idx\n",
    "            )\n",
    "            writer.add_scalar(\n",
    "                \"Train/accuracy\", train_acc, epoch * len(train_loader) + idx\n",
    "            )\n",
    "\n",
    "            loss_value = 0\n",
    "            matches = 0\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # val loop\n",
    "    with torch.no_grad():\n",
    "        print(\"Calculating validation results...\")\n",
    "        model.eval()\n",
    "        val_loss_items = []\n",
    "        val_acc_items = []\n",
    "        figure = None\n",
    "\n",
    "        for inputs, labels in val_loader:\n",
    "            # Move the batch to the device\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outs = model(inputs)\n",
    "            preds = torch.argmax(outs, dim=-1)\n",
    "\n",
    "            loss_item = criterion(outs, labels).item()\n",
    "            acc_item = (labels == preds).sum().item()\n",
    "            val_loss_items.append(loss_item)\n",
    "            val_acc_items.append(acc_item)\n",
    "\n",
    "            if figure is None:\n",
    "                inputs_np = (\n",
    "                    torch.clone(inputs).detach().cpu().permute(0, 2, 3, 1).numpy()\n",
    "                )\n",
    "                inputs_np = MaskBaseDataset.denormalize_image(\n",
    "                    inputs_np, dataset.mean, dataset.std\n",
    "                )\n",
    "                figure = grid_image(\n",
    "                    inputs_np,\n",
    "                    labels,\n",
    "                    preds,\n",
    "                    n=16,\n",
    "                    shuffle=True,\n",
    "                )\n",
    "\n",
    "        val_loss = np.sum(val_loss_items) / len(val_loader)\n",
    "        val_acc = np.sum(val_acc_items) / len(val_set)\n",
    "        best_val_loss = min(best_val_loss, val_loss)\n",
    "        if val_acc > best_val_acc:\n",
    "            print(\n",
    "                f\"New best model for val accuracy : {val_acc:4.2%}! saving the best model..\"\n",
    "            )\n",
    "            torch.save(model.module.state_dict(), f\"{save_dir}/best.pth\")\n",
    "            best_val_acc = val_acc\n",
    "\n",
    "        torch.save(model.module.state_dict(), f\"{save_dir}/last.pth\")\n",
    "        print(\n",
    "            f\"[Val] acc : {val_acc:4.2%}, loss: {val_loss:4.2} || \"\n",
    "            f\"best acc : {best_val_acc:4.2%}, best loss: {best_val_loss:4.2}\"\n",
    "        )\n",
    "\n",
    "        writer.add_scalar(\"Val/loss\", val_loss, epoch)\n",
    "        writer.add_scalar(\"Val/accuracy\", val_acc, epoch)\n",
    "        writer.add_figure(\"results\", figure, epoch)\n",
    "        print()\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515499c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
